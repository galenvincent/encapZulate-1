{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=tf_config)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras import layers, models, optimizers, regularizers\n",
    "from keras.initializers import Constant\n",
    "from keras.callbacks import CSVLogger, LearningRateScheduler, ModelCheckpoint\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import (\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    Conv1D,\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Lambda,\n",
    "    Layer,\n",
    "    MaxPooling2D,\n",
    "    PReLU,\n",
    "    Reshape,\n",
    "    Softmax,\n",
    ")\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_photoz = \"/home/bid13/code/photozCapsNet\"\n",
    "\n",
    "sys.path.insert(1, path_photoz)\n",
    "path_photoz = Path(path_photoz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encapzulate\n",
    "from encapzulate.base.deepCapsLayers import (\n",
    "    CapsToScalars,\n",
    "    CapsuleLayer,\n",
    "    Conv2DCaps,\n",
    "    ConvCapsuleLayer3D,\n",
    "    ConvertToCaps,\n",
    "    FlattenCaps,\n",
    "    Mask_CID,\n",
    ")\n",
    "from encapzulate.base.loss import margin_loss\n",
    "from encapzulate.data_loader.data_loader import load_data\n",
    "from encapzulate.models.multi_gpu import MultiGPUModel\n",
    "from encapzulate.utils import metrics\n",
    "from encapzulate.utils.fileio import load_config, load_model\n",
    "from encapzulate.utils.metrics import Metrics, bins_to_redshifts, probs_to_redshifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import normalization\n",
    "reload(normalization)\n",
    "from normalization import LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "config:\n",
      "{   'bands': ('u', 'g', 'r', 'i', 'z'),\n",
      "    'batch_size': 400,\n",
      "    'checkpoint': None,\n",
      "    'compile_on': 'cpu',\n",
      "    'dataset': 'sdss_gz1_iter1',\n",
      "    'decay_rate': 0.95,\n",
      "    'dim_capsule': 16,\n",
      "    'epochs': 100,\n",
      "    'frac_dev': 0.1,\n",
      "    'frac_train': 0.2,\n",
      "    'image_scale': 10,\n",
      "    'image_shape': (64, 64, 5),\n",
      "    'img_augmentation': 2,\n",
      "    'lam_recon': 0.005,\n",
      "    'lam_redshift': 1,\n",
      "    'learning_rate': 0.001,\n",
      "    'logistic': True,\n",
      "    'model_name': 'morphCapsDeep_2',\n",
      "    'num_class': 2,\n",
      "    'num_gpus': 2,\n",
      "    'num_quantiles': False,\n",
      "    'path_data': '/data/bid13/photoZ/data/pasquet2019',\n",
      "    'path_results': None,\n",
      "    'random_state': 200,\n",
      "    'routings': 3,\n",
      "    'run_name': 'morphCapsDeep_multi_val_5',\n",
      "    'timeline': False,\n",
      "    'use_vals': False,\n",
      "    'z_max': 0.4,\n",
      "    'z_min': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = load_config(path_photoz / \"encapzulate\" / \"configs\" / \"morphCaps.yml\")\n",
    "config[\"run_name\"] = 'morphCapsDeep_multi_val_0'\n",
    "# config[\"dataset\"] = \"sdss_GZ_weighted_regression\"\n",
    "# config[\"path_data\"] = \"/data/bid13/photoZ/data/pasquet2019\"\n",
    "config[\"input_shape\"] = config[\"image_shape\"]\n",
    "# config[\"run_name\"] = \"test\"\n",
    "# config[\"reg_weight\"] = 1.0\n",
    "config[\"epochs\"] = 4\n",
    "# config[\"num_class\"] = 3\n",
    "# config[\"learning_rate\"] = 0.001\n",
    "# config[\"decay_rate\"] = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = \"/home/bid13/code/photozCapsNet/results\"\n",
    "path_output = Path(path_output)\n",
    "path_results = (\n",
    "    path_output / config[\"run_name\"].split(\"_\")[0] / config[\"run_name\"] / \"results\"\n",
    ")\n",
    "path_logs = path_results / \"logs\"\n",
    "path_weights = path_results / \"weights\"\n",
    "path_logs.mkdir(parents=True, exist_ok=True)\n",
    "path_weights.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (x_train, y_train, vals_train, z_spec_train, cat_train),\n",
    "    (x_dev, y_dev, vals_dev, z_spec_dev, cat_dev),\n",
    "    (x_test, y_test, vals_test, z_spec_test, cat_test),\n",
    ") = load_data(load_cat=True, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_train = np.isfinite(vals_train).all(axis=1)\n",
    "# mask_test = np.isfinite(vals_test).all(axis=1)\n",
    "# mask_dev = np.isfinite(vals_dev).all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMultiLossLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomMultiLossLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape=None):\n",
    "        # initialise log_vars\n",
    "        self.hinge_log_var = self.add_weight(\n",
    "            name=\"hinge_log_var\", shape=(1,), initializer=Constant(0.0), trainable=True\n",
    "        )\n",
    "        self.decoder_log_var = self.add_weight(\n",
    "            name=\"decoder_log_var\",\n",
    "            shape=(1,),\n",
    "            initializer=Constant(0.0),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.redshift_log_var = self.add_weight(\n",
    "            name=\"redshift_log_var\",\n",
    "            shape=(1,),\n",
    "            initializer=Constant(0.0),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        super(CustomMultiLossLayer, self).build(input_shape)\n",
    "\n",
    "    def multi_loss(self, x_true, y_true, z_true, x_pred, y_pred, z_pred):\n",
    "        hinge_ivar = K.exp(-self.hinge_log_var)\n",
    "        loss = K.sum(\n",
    "            hinge_ivar * margin_loss(y_true, y_pred) + self.hinge_log_var, axis=-1\n",
    "        )\n",
    "\n",
    "        decoder_ivar = K.exp(-self.decoder_log_var)\n",
    "        loss += K.sum(\n",
    "            decoder_ivar * K.sum((x_true - x_pred) ** 2.0) + self.decoder_log_var, axis=-1\n",
    "        )\n",
    "\n",
    "        redshift_ivar = K.exp(-self.redshift_log_var)\n",
    "        loss += K.sum(\n",
    "            redshift_ivar * (z_true - z_pred) ** 2.0 + self.redshift_log_var, axis=-1\n",
    "        )\n",
    "        \n",
    "\n",
    "        return K.mean(loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_true, y_true, z_true, x_pred, y_pred, z_pred = inputs\n",
    "        loss = self.multi_loss(x_true, y_true, z_true, x_pred, y_pred, z_pred)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return z_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapsNet(input_shape, num_class, routings, dim_capsule, **kwargs):\n",
    "    # assemble encoder\n",
    "    x = Input(shape=input_shape)\n",
    "    l = x\n",
    "\n",
    "    l = Conv2D(\n",
    "        128,\n",
    "        (3, 3),\n",
    "        strides=(1, 1),\n",
    "        activation=\"relu\",\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(\n",
    "        l\n",
    "    )  # common conv layer\n",
    "    l = BatchNormalization()(l)\n",
    "    l = ConvertToCaps()(l)\n",
    "\n",
    "    l = Conv2DCaps(\n",
    "        32, 4, kernel_size=(3, 3), strides=(2, 2), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l_skip = Conv2DCaps(\n",
    "        32, 4, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 4, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 4, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = layers.Add()([l, l_skip])\n",
    "\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(2, 2), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l_skip = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = layers.Add()([l, l_skip])\n",
    "\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(2, 2), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l_skip = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = layers.Add()([l, l_skip])\n",
    "    l1 = l\n",
    "\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(2, 2), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l_skip = ConvCapsuleLayer3D(\n",
    "        kernel_size=3,\n",
    "        num_capsule=32,\n",
    "        num_atoms=8,\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        routings=3,\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = layers.Add()([l, l_skip])\n",
    "    l2 = l\n",
    "\n",
    "    la = FlattenCaps()(l2)\n",
    "    lb = FlattenCaps()(l1)\n",
    "    l = layers.Concatenate(axis=-2)([la, lb])\n",
    "\n",
    "    #     l = Dropout(0.4)(l)\n",
    "    digits_caps = CapsuleLayer(\n",
    "        num_capsule=num_class,\n",
    "        dim_capsule=dim_capsule,\n",
    "        routings=routings,\n",
    "        channels=0,\n",
    "        name=\"digit_caps\",\n",
    "    )(l)\n",
    "\n",
    "    l = CapsToScalars(name=\"capsnet\")(digits_caps)\n",
    "    # l = Softmax()(l)\n",
    "\n",
    "    m_capsnet = models.Model(inputs=x, outputs=l, name=\"capsnet_model\")\n",
    "\n",
    "    y = Input(shape=(num_class,))\n",
    "\n",
    "    masked_by_y = Mask_CID()([digits_caps, y])\n",
    "    masked = Mask_CID()(digits_caps)\n",
    "\n",
    "    # Redshift Network\n",
    "    z = Input(shape=(1,))\n",
    "    redshift_input = Input(shape=(dim_capsule,))\n",
    "    #     r = LayerNormalization()(redshift_input)\n",
    "    #     r = BatchNormalization(momentum=0.9)(redshift_input)\n",
    "    r = Dense(128, kernel_initializer=\"he_normal\")(redshift_input)\n",
    "    r = PReLU()(r)\n",
    "    r = Dense(64, kernel_initializer=\"he_normal\")(r)\n",
    "    r = PReLU()(r)\n",
    "    r = Dense(32, kernel_initializer=\"he_normal\")(r)\n",
    "    r = PReLU()(r)\n",
    "    r = Dense(16, kernel_initializer=\"he_normal\")(r)\n",
    "    r = PReLU()(r)\n",
    "    redshift_out = Dense(1)(r)\n",
    "    #     redshift_out = Dense(1)(redshift_input)\n",
    "    redshift = models.Model(redshift_input, redshift_out, name=\"redshift_model\")\n",
    "\n",
    "    # Decoder Network\n",
    "    decoder_input = Input(shape=(dim_capsule,))\n",
    "    d = Dense(np.prod(input_shape), kernel_initializer=\"he_normal\",)(decoder_input)\n",
    "    d = PReLU()(d)\n",
    "    d = Reshape(input_shape)(d)\n",
    "\n",
    "    d = Conv2DTranspose(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",)(d)\n",
    "    d = PReLU()(d)\n",
    "    d = Conv2DTranspose(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",)(d)\n",
    "    d = PReLU()(d)\n",
    "    d = Conv2DTranspose(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",)(d)\n",
    "    d = PReLU()(d)\n",
    "    d = Conv2DTranspose(8, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")(d)\n",
    "    d = PReLU()(d)\n",
    "    d = Conv2DTranspose(\n",
    "        input_shape[-1],\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        activation=\"tanh\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(d)\n",
    "    decoder_output = Reshape(target_shape=input_shape, name=\"out_recon\")(d)\n",
    "\n",
    "    decoder = models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
    "\n",
    "    loss_layer = CustomMultiLossLayer()(\n",
    "        [x, y, z, decoder(masked_by_y), m_capsnet.output, redshift(masked_by_y)]\n",
    "    )\n",
    "\n",
    "    train_model = models.Model([x, y, z], [loss_layer],)\n",
    "\n",
    "    # Add required metrics for monitoring training\n",
    "    train_model.add_metric((z - redshift(masked)) ** 2, name=\"redshift_loss\")\n",
    "    if kwargs[\"logistic\"]:\n",
    "        inv_log_z_true = (K.exp(z) * kwargs[\"z_max\"] + kwargs[\"z_min\"]) / (K.exp(z) + 1)\n",
    "        inv_log_z_pred = (\n",
    "            K.exp(redshift(masked)) * kwargs[\"z_max\"] + kwargs[\"z_min\"]\n",
    "        ) / (K.exp(redshift(masked)) + 1)\n",
    "        train_model.add_metric(\n",
    "            (inv_log_z_true - inv_log_z_pred) ** 2, name=\"redshift_mse\"\n",
    "        )\n",
    "    train_model.add_metric((x - decoder(masked)) ** 2, name=\"decoder_mse\")\n",
    "    train_model.add_metric(\n",
    "        tf.cast(\n",
    "            tf.equal(\n",
    "                tf.compat.v1.argmax(y, axis=-1),\n",
    "                tf.compat.v1.argmax(m_capsnet.output, axis=-1),\n",
    "            ),\n",
    "            K.floatx(),\n",
    "        ),\n",
    "        name=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    eval_model = models.Model(\n",
    "        [x,],\n",
    "        [masked, digits_caps, m_capsnet.output, decoder(masked), redshift(masked),],\n",
    "    )\n",
    "\n",
    "    manipulate_model = models.Model(\n",
    "        [x,], [masked, m_capsnet.output, decoder(masked), redshift(masked)],\n",
    "    )\n",
    "    train_model.summary()\n",
    "\n",
    "    return train_model, eval_model, manipulate_model, decoder, redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/tf15/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Tensor(\"conv_capsule_layer3d_1/stack:0\", shape=(5,), dtype=int32)\n",
      "WARNING:tensorflow:From /home/bid13/code/photozCapsNet/encapzulate/base/deepCapsLayers.py:446: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 128)  5888        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convert_to_caps_1 (ConvertToCap (None, 64, 64, 128,  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_1 (Conv2DCaps)      (None, 32, 32, 32, 4 147456      convert_to_caps_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_3 (Conv2DCaps)      (None, 32, 32, 32, 4 147456      conv2d_caps_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_4 (Conv2DCaps)      (None, 32, 32, 32, 4 147456      conv2d_caps_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_2 (Conv2DCaps)      (None, 32, 32, 32, 4 147456      conv2d_caps_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 32, 4 0           conv2d_caps_4[0][0]              \n",
      "                                                                 conv2d_caps_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_5 (Conv2DCaps)      (None, 16, 16, 32, 8 294912      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_7 (Conv2DCaps)      (None, 16, 16, 32, 8 589824      conv2d_caps_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_8 (Conv2DCaps)      (None, 16, 16, 32, 8 589824      conv2d_caps_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_6 (Conv2DCaps)      (None, 16, 16, 32, 8 589824      conv2d_caps_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 32, 8 0           conv2d_caps_8[0][0]              \n",
      "                                                                 conv2d_caps_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_9 (Conv2DCaps)      (None, 8, 8, 32, 8)  589824      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_11 (Conv2DCaps)     (None, 8, 8, 32, 8)  589824      conv2d_caps_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_12 (Conv2DCaps)     (None, 8, 8, 32, 8)  589824      conv2d_caps_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_10 (Conv2DCaps)     (None, 8, 8, 32, 8)  589824      conv2d_caps_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 32, 8)  0           conv2d_caps_12[0][0]             \n",
      "                                                                 conv2d_caps_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_13 (Conv2DCaps)     (None, 4, 4, 32, 8)  589824      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_14 (Conv2DCaps)     (None, 4, 4, 32, 8)  589824      conv2d_caps_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_15 (Conv2DCaps)     (None, 4, 4, 32, 8)  589824      conv2d_caps_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_capsule_layer3d_1 (ConvCap (None, 4, 4, 32, 8)  18688       conv2d_caps_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 32, 8)  0           conv2d_caps_15[0][0]             \n",
      "                                                                 conv_capsule_layer3d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_caps_1 (FlattenCaps)    (None, 512, 8)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_caps_2 (FlattenCaps)    (None, 2048, 8)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2560, 8)      0           flatten_caps_1[0][0]             \n",
      "                                                                 flatten_caps_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "digit_caps (CapsuleLayer)       (None, 2, 16)        655392      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask_cid_1 (Mask_CID)           (None, 16)           0           digit_caps[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_model (Model)           (None, 64, 64, 5)    887717      mask_cid_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (CapsToScalars)         (None, 2)            0           digit_caps[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "redshift_model (Model)          (None, 1)            13297       mask_cid_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "custom_multi_loss_layer_1 (Cust [(None, 64, 64, 5),  3           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 decoder_model[1][0]              \n",
      "                                                                 capsnet[0][0]                    \n",
      "                                                                 redshift_model[1][0]             \n",
      "==================================================================================================\n",
      "Total params: 8,364,473\n",
      "Trainable params: 8,364,217\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "Tensor(\"replica_0/model_1/conv_capsule_layer3d_1/stack:0\", shape=(5,), dtype=int32, device=/device:GPU:0)\n",
      "Tensor(\"replica_1/model_1/conv_capsule_layer3d_1/stack:0\", shape=(5,), dtype=int32, device=/device:GPU:1)\n"
     ]
    }
   ],
   "source": [
    "train_model, eval_model, manipulate_model, decoder, redshift_model = CapsNet(**config)\n",
    "parallel_train_model = MultiGPUModel(train_model, gpus=2)\n",
    "train_model = parallel_train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf15/lib/python3.6/site-packages/keras/engine/training_utils.py:819: UserWarning: Output custom_multi_loss_layer_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_multi_loss_layer_1.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    }
   ],
   "source": [
    "compile_kwargs = {\n",
    "    \"optimizer\": optimizers.Adam(lr=config[\"learning_rate\"]),\n",
    "#     \"loss\": None,#[margin_loss, \"mse\", \"mse\"],\n",
    "#     \"loss_weights\": None, #[\n",
    "# #         1.0,\n",
    "# #         config[\"lam_recon\"] * np.prod(config[\"input_shape\"]),\n",
    "# #         config[\"lam_redshift\"],\n",
    "# #     ],\n",
    "#      \"metrics\": {\"capsnet\": \"accuracy\",},\n",
    "}\n",
    "train_model.compile(**compile_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/tf15/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tf15/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 92171 samples, validate on 46086 samples\n",
      "Epoch 1/4\n",
      "92171/92171 [==============================] - 326s 4ms/step - loss: 19614.8566 - redshift_loss: 0.5352 - redshift_mse: 0.0029 - decoder_mse: 0.0025 - accuracy: 0.6526 - val_loss: 11601.1991 - val_redshift_loss: 0.6835 - val_redshift_mse: 0.0034 - val_decoder_mse: 0.0015 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00001: saving model to /home/bid13/code/photozCapsNet/results/morphCapsDeep/morphCapsDeep_multi_val_0/results/weights/weights-01.h5\n",
      "Epoch 2/4\n",
      "92171/92171 [==============================] - 317s 3ms/step - loss: 10095.9203 - redshift_loss: 0.5480 - redshift_mse: 0.0027 - decoder_mse: 0.0014 - accuracy: 0.3832 - val_loss: 10602.9034 - val_redshift_loss: 0.7389 - val_redshift_mse: 0.0035 - val_decoder_mse: 0.0015 - val_accuracy: 0.3233\n",
      "\n",
      "Epoch 00002: saving model to /home/bid13/code/photozCapsNet/results/morphCapsDeep/morphCapsDeep_multi_val_0/results/weights/weights-02.h5\n",
      "Epoch 3/4\n",
      "92171/92171 [==============================] - 317s 3ms/step - loss: 9076.0147 - redshift_loss: 0.5532 - redshift_mse: 0.0027 - decoder_mse: 0.0013 - accuracy: 0.3325 - val_loss: 9705.8475 - val_redshift_loss: 0.8427 - val_redshift_mse: 0.0041 - val_decoder_mse: 0.0014 - val_accuracy: 0.3235\n",
      "\n",
      "Epoch 00003: saving model to /home/bid13/code/photozCapsNet/results/morphCapsDeep/morphCapsDeep_multi_val_0/results/weights/weights-03.h5\n",
      "Epoch 4/4\n",
      "67600/92171 [=====================>........] - ETA: 1:02 - loss: 8422.4875 - redshift_loss: 0.6985 - redshift_mse: 0.0035 - decoder_mse: 0.0012 - accuracy: 0.3232"
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "lr_decay = LearningRateScheduler(\n",
    "    schedule=lambda epoch: config[\"learning_rate\"] * (config[\"decay_rate\"] ** epoch)\n",
    ")\n",
    "log = CSVLogger(str(path_logs / \"log.csv\"))\n",
    "cp = ModelCheckpoint(\n",
    "    filepath=str(path_weights / \"weights-{epoch:02d}.h5\"),\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "\n",
    "train_model.fit(\n",
    "    x=[x_train, y_train, z_spec_train],\n",
    "    y = None,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    validation_data=[[x_dev,y_dev, z_spec_train], None,],\n",
    "    epochs=config[\"epochs\"],\n",
    "    initial_epoch=0,\n",
    "    callbacks=[log, cp, lr_decay],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv(path_results / \"logs\" / \"log.csv\")\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf15",
   "language": "python",
   "name": "tf15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
